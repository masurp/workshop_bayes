<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Bayesian Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Philipp K. Masur" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: left, middle, title-slide

.title[
# Introduction to Bayesian Statistics
]
.author[
### Philipp K. Masur
]
.date[
### Mainz | 10.-11. October 2022
]

---








class: inverse, center, middle

# Welcome

Why are you interested in Bayesian Statistics?

Any prior experience?


---

# Expectations and overview

.pull-left[

### What we will cover

- Bayes Theorem and Bayesian Inference

- How to run (generalized) linear models using 'brms'

- How to specify priors and interpret results

- How to draw probabilistic inferences from results

]

.pull-left[

### What we will NOT cover

- Introduction to R &amp; Data Wrangling in R

- Introduction to (generalized linear models)

- Bayes factors (a.k.a Bayesian p-values)

- More complex models

]



---

# Overview

- A lot of theory, but also practical sessions

- First day: Understanding Bayesian Inference

- Second day: Doing stuff in R!

- Please ask questions


---
.pull-left[

### Monday


|Time                   |Topic                          |
|:----------------------|:------------------------------|
|[9:00 - 9:30:](#s1)    |Welcome                        |
|[9:30 - 10:30:](#s2)   |An Introductory Example        |
|[10:30 - 11:30.](#s3)  |Basics of Bayesian Statistics  |
|[11:30 -  13:00.](#s4) |Understanding Priors           |
|13:00 - 14:00:         |Lunch                          |
|[14:00 - 14:45:](#s5)  |NHST vs Bayesian Inference     |
|[14:45 - 15:30:](#s6)  |Exercise I                     |
|15:30 - 16:00:         |Coffee                         |
|[16:00 - 17:00:](#s7)  |A Bit of R and Intro to 'brms' |

]

.pull-right[

### Tuesday


|Time                   |Topic                          |
|:----------------------|:------------------------------|
|[9:00 - 9:30:](#s1)    |Short Recap                    |
|[9:30 - 10:30:](#s2)   |Defining Priors                |
|[10:30 - 11:30.](#s3)  |Simple and Multiple Regression |
|[11:30 -  13:00.](#s4) |Exercise II                    |
|13:00 - 14:00:         |Lunch                          |
|[14:00 - 14:45:](#s5)  |Multilevel Regression          |
|[14:45 - 15:30:](#s6)  |Exercise III                   |
|15:30 - 16:00:         |Coffee                         |
|[16:00 - 17:00:](#s7)  |Q&amp;A'                           |


]

---

# Literature

.pull-left[

- My slides are based on this book by Kruschke...

- ... and its translation to "brms" by Salomon Kurz ([see here](https://bookdown.org/content/3686/))

- Great and comparatively simple introduction

- Lots of examples (including R code)

]

.pull-right[
![](https://m.media-amazon.com/images/I/41je2iREauL._AC_SY580_.jpg)
]


---

class: inverse, center, middle

# An Introductory Example

"The Geometry of Changing Beliefs"

---

# Example: Covid-19 Rapid Test

.pull-left[

Philipp is generally **a conscientious and orderly** person. Today, he has taken a Corona self-test as he regularly does. To his surprise, the **self-test is positive**. He remembers vaguely that such tests have **a sensitivity of 95%**, i.e. they are very good at picking up the disease. Thinking about it, he actually has been **coughing** a bit lately. He immediately isolates himself and wonders:

&lt;br&gt;

What is the probability of the rapid test result being correct?

]

.pull-right[

![](img/boy.png)

]




---

# Intuition?

![](material/ppt_templates/Slide01.png)


---

# Reality

- We fail to acknowledge the true prevalence of the disease in the population. 

- Let's imagine for now that it is 4.8% in the population (an infection rate of 4800; currently it is rather 300, thus 0.3%)




![](material/ppt_templates/Slide02.png)
---

# New knowledge = observing evidence

- We have observed a positive test result 

- We know that the sensitivity and of such test is 95%: In 95 out of 100 cases, the test correctly identifies an infected person as positive.

![](material/ppt_templates/Slide03.png)

---

# What else?

- Such test also have a certain specificity (i.e., ability to correctly identify people who DON'T have the disease), which is also 95%. 

- This means, they produce false positives in 5% of the cases.

![](material/ppt_templates/Slide04.png)
---

# What is the true probability?

![](material/ppt_templates/Slide05.png)
---

# Non-Bayesian Thinking...

![](material/ppt_templates/Slide06.png)
---

# Bayesian Thinking: Updating beliefs

![](material/ppt_templates/Slide07.png)

---

# When should we use the Bayes Theorem?

![](material/ppt_templates/Slide08.png)

---

# How does this translate into the formula?

![](material/ppt_templates/Slide09.png)
---
# How does this translate into the formula?

![](material/ppt_templates/Slide10.png)
---
# How does this translate into the formula?

![](material/ppt_templates/Slide11.png)
---
# Multiplying probabilities

![](material/ppt_templates/Slide12.png)

---

# With actual numbers

![](material/ppt_templates/Slide13.png)
---

# The Bayes Theorem

![](material/ppt_templates/Slide14.png)
---

# Practical example: Naive Bayes classifier

.pull-left[

- Computes the prior probability ( _P_ ) for every category ( _c_ = outcome variable ) based on the training data set

- Computes the probability of every feature ( _x_ ) to be a characteristic of the class ( _c_ ); i.e., the relative frequency of the feature in category

- For every probability of a category in light of certain features ( _P(c|X)_ ), all feature probabilities ( _x_ ) are multiplied

- The algorithm hence chooses the class that has highest weighted sum of inputs

]

.pull-right[

![](https://s3.ap-south-1.amazonaws.com/techleer/204.png)


]

---

# A Short History of Bayesian Statistics

.pull-left[

- Thomas Bayes (1702-1761) was an English mathematician and presbyterian priest who came up with the idea of "inverse probability"

- "An essay towards solving a problem in the doctrine of chances" includes a special cases of the Bayes theorem and was published posthum in 1764 by his friend Richard Price

- Pierre-Simon Laplace (1749-1827) further develops the idea of "inverse probability"

- 1980s: Increase in use of Bayesian statistics due to Markov Chain Monte Carlo methods (computational feasability)

]
 

.pull-right[

![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif)

]

---

class: inverse, center, middle

# Basics of Bayesian Statistics

---

class: center, middle

# What is probability?


---

# Probability

- A long-run relative frequency
    - according to frequentist statistics (Fisher, Person, Neyman...)

&lt;br&gt;&lt;br&gt;

--

- A subjective belief
    - according to Bayesian statistics (Bayes, Laplace...)

---

# Frequentist statistics explained

.pull-left[
- The "classic" statistical framework

- Is based on the idea of repeated sampling from a population

- Population parameters are fixed, actually exist

- Probability refers to the long-run frequency of a given event

- Data are random, result from sampling a fixed population distribution

]

.pull-right[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-4-1.png" width="100%" /&gt;

]
---
# Sampling from the population

&lt;img src="slides_01_files/figure-html/unnamed-chunk-5-1.png" width="100%" /&gt;


---

# Parameter distribution

.pull-left[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-6-1.png" width="100%" /&gt;

]

.pull-right[


- According to the central limit theorem, the means are distributed around the true population parameter *M* = 680. 

- The standard error (*SE* = `\(SD(x)/\sqrt(n-1)\)`), which we can computed based on a single sample, is an estimate for the variance of this mean distribution

- In our first sample, the standard error is *SE* = `\(164/\sqrt(50-1)\)` = 27.3
]

---
# Conceptual Framework of Bayesian Data Analysis

&lt;br&gt;&lt;br&gt;

&gt; Bayesian data analysis has two foundational ideas. The first idea is that Bayesian inference is *reallocation of credibility* across possibilities. The second foundational idea is that the possibilities, over which we allocate credibility, are *parameter values in meaningful mathematical models*. (Kruschke, 2015, p. 15)

---

# Reallocation of credibility across possibilites

.pull-left[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-7-1.png" width="100%" /&gt;
]

--

.pull-right[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-8-1.png" width="100%" /&gt;

]

---

# Logic of Bayesian Inference


- the essence of Bayesian inference is reallocation of credibility across possibilities

- The distribution of credibility initially reflects prior knowledge about the possibilities (which can be quite vague). 

- Then new data are observed, and the credibility is re-allocated. 

- Possibilities that are consistent with the data garner more credibility, while possibilities that are not consistent with the data lose credibility. 

- Bayesian analysis is the mathematics of re-allocating credibility in a logically coherent and precise way. 

_(Kruschke, 2015, p. 22)_

---


# Steps of Bayesian Data Analysis

1. Identify the **data relevant to the research questions**. What are the measurement scales of the data? Which data variables are to be predicted, and which data variables are supposed to act as predictors?

2. Define a **descriptive model** for the relevant data. The mathematical form and its parameters should be meaningful and appropriate to the theoretical purposes of the analysis.

3. Specify a **prior distribution** on the parameters. The prior must pass muster with the audience of the analysis, such as skeptical scientists.

4. Use Bayesian inference to **re-allocate credibility** across parameter values. Interpret the posterior distribution with respect to theoretically meaningful issues (assuming that the model is a reasonable description of the data; see next step).

5. Check that the **posterior predictions** mimic the data with reasonable accuracy (i.e., conduct a “posterior predictive check”). If not, then consider a different descriptive model.

---

# An example: Social media use and well-being


```
# A tibble: 50 × 2
       use    wb
     &lt;dbl&gt; &lt;dbl&gt;
 1  1.37    3.42
 2 -0.565   3.2 
 3  0.363   4.55
 4  0.633   3.84
 5  0.404   3.53
 6 -0.106   3.79
 7  1.51    3.63
 8 -0.0947  3.66
 9  2.02    1   
10 -0.0627  3.79
# … with 40 more rows
```

---

# Frequentist linear regression

.pull-left[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-10-1.png" width="100%" /&gt;

]

.pull-left[

- We can define this model with the following formula:

`\(y_i = \beta_0 + \beta_1x + \epsilon\)`

- or alternatively as:

`\(y_i = \beta_0 + \beta_1x\)`

`\(y \sim normal(y_i, \sigma)\)`

]


---

# Bayesian linear regression

.pull-left[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-11-1.png" width="100%" /&gt;

]

.pull-right[

&lt;img src="slides_01_files/figure-html/unnamed-chunk-12-1.png" width="100%" /&gt;

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": false,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
